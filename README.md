## Overview

Our aim is to determine if AI-generated titles closely match the abstract (i.e., the content) of the overall information that is meant to be conveyed on a research paper compared to that of human-generated titles. We argue that Large Language Models (LLMs) have transformed research focus, dissemination, and readability patterns across all research areas. For our experiments, we focus on these five selected knowledge areas:

- Business Administration and Management (BAM)
- Computer Science and Information Technology (CS)
- Engineering and Material Science (EMS)
- Medicine and Healthcare (MH)
- Psychology and Behavioral Sciences (PBS)

## Scope

Our primary scope is to investigate the titles and abstracts of academic papers in these domains, distinguishing those published before (PRELLM) and during the era of Large Language Models (LLMERA).

## This Profile

In this profile, we present the datasets and code used for generating the scores that we analyzed in our paper titled "Impact of Large Language Models on Scholarly Publication Titles and Abstracts: A Comparative Analysis".

## Citation

If you use any part of these datasets or code in your work, please cite our paper:
P. L. Teh and C. F. Uwasomba, "Impact of Large Language Models on Scholarly Publication Titles and Abstracts: A Comparative Analysis," in Journal of Social Computing, vol. 5, no. 2, pp. 105-121, June 2024, doi: 10.23919/JSC.2024.0011. 
